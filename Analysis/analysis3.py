# -*- coding: utf-8 -*-
"""Analysis3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yEJ94g2UgdLjXmOAgtx9-cUeX27n_ohC
"""

#import libraries
import pandas as pd
import spacy
import matplotlib.pyplot as plt
import seaborn as sns
import os
import numpy as np

#load dataset
df = pd.read_csv("new_words.csv")

df.head()

#remove digits from the 'word' column using regex
df['word'] = df['word'].str.replace('\d+', '')

#find the empty columns
empty_cols = [col for col in df.columns if df[col].isnull().all()]

#drop the empty columns
df.drop(empty_cols, axis=1, inplace=True)

"""##Extract Speed of words"""

#compute min and max values of the duration column
min_duration = df["duration"].min()
max_duration = df["duration"].max()

#apply min-max normalization to the duration column
df["duration_norm"] = (df["duration"] - min_duration) / (max_duration - min_duration)

#divide the range into three bins and assign categories
bins = [0, 0.33, 0.67, 1]
labels = ["fast", "medium", "slow"]
df["word_speed"] = pd.cut(df["duration_norm"], bins=bins, labels=labels)

#print the resulting dataframe
df

"""The words were categorised based on speed using min-max normalisation, according to their word duration."""

duration_counts = df['word_speed'].value_counts()
duration_counts

#select the rows with the "slow" duration category
df_slow = df.loc[df['word_speed'] == 'medium']

slow_texts = df_slow['word'].tolist()

print(slow_texts)

#make a copy of the dataframe
df_a =df.copy()

#drop the column duration_norm
df_a=df_a.drop('duration_norm', axis=1)

"""The duration_norm column was dropped as it was no longer required

##Extract the vowels of words
"""

#extract vowels of words
import re

#define regular expression patterns for matching vowels
vowel_pattern = re.compile('[AEIOUaeiou]')

#define a function to categorise a word based on its unique vowels
def categorize_vowels(word):
    vowels = set(vowel_pattern.findall(word))
    num_vowels = len(vowels)
    if num_vowels == 0:
        return 'No vowels'
    elif num_vowels == 1:
        return '1 vowel ({})'.format(list(vowels)[0])
    else:
        unique_vowels = ''.join(sorted(vowels))
        return '{} vowels ({})'.format(num_vowels, unique_vowels)

df_a['vowel_category'] = df_a['word'].apply(categorize_vowels)

#save the word categories
df_a.to_csv('word_categories.csv', index=False)

df_a.head(10)

"""Vowels were extracted from the words and grouped based on the number of vowels in a word

##Extract the length of words
"""

#define a function to categorise a word based on its character count
def categorize_word(word):
    word_length = len(word)
    if word_length < 5:
        return 'Short'.format(word_length)
    elif word_length >= 5 and word_length <= 7:
        return 'Medium'.format(word_length)
    else:
        return 'Long'.format(word_length)

df_a['character_count'] = df_a['word'].apply(lambda x: len(x))
df_a['length_category'] = df_a['word'].apply(categorize_word)

df_a.head(10)

"""words were grouped into length, based on the character count of a word

##Extract the Part of Speech of words
"""

import nltk

#download the NLTK part-of-speech tagger
nltk.download('averaged_perceptron_tagger')

#define function to get part-of-speech tags for words
def get_pos_tag(word):
    pos_tags = nltk.pos_tag([word])
    return pos_tags[0][1]

#create a new column to save the part-of-speech tags
df_a['part_of_speech'] = df_a['word'].apply(get_pos_tag)

df_a.head(10)

#define a dictionary to map part-of-speech tags to their labels
pos_mapping = {
    'NN': 'Noun',
    'VB': 'Verb',
    'JJ': 'Adjective',
    'RB': 'Adverb',
    'PRP': 'Pronoun',
    'IN': 'Preposition'
}

#function to map part-of-speech tags or return blank for unspecified tags
def map_pos(pos):
    return pos_mapping.get(pos, '')

#map the part-of-speech tags to their labels
df_a['part_of_speech'] = df_a['part_of_speech'].map(map_pos)

df_a

#make a copy of the dataframe
df_b = df_a.copy()

df_b.head(5)

#save the dataframe to a csv file
df_b.to_csv('categories.csv', index=False)